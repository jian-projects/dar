{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzq/anaconda3/envs/sa/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 12475693.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 3830862.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 3282490.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 7924512.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw\n",
      "\n",
      "tensor([5, 0, 4,  ..., 5, 6, 8])\n",
      "tensor([7, 2, 1,  ..., 4, 5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/jzq/anaconda3/envs/sa/lib/python3.8/site-packages/torchvision/datasets/mnist.py:65: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/home/jzq/anaconda3/envs/sa/lib/python3.8/site-packages/torchvision/datasets/mnist.py:70: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "project_root = '.'\n",
    "os.chdir(project_root)\n",
    "\n",
    "no_cuda = False\n",
    "cuda_available = not no_cuda and torch.cuda.is_available()\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 100\n",
    "SEED = 8\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if cuda_available else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda_available else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./MNIST_data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./MNIST_data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "print(train_loader.dataset.train_labels)\n",
    "print(test_loader.dataset.test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CVAE, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(794, 400)\n",
    "        self.fc21 = nn.Linear(400, 20)\n",
    "        self.fc22 = nn.Linear(400, 20)\n",
    "        self.fc3 = nn.Linear(30, 400)\n",
    "        self.fc4 = nn.Linear(400, 794)\n",
    "        \n",
    "        self.lb = LabelBinarizer()\n",
    "    #将标签进行one-hot编码\n",
    "    def to_categrical(self, y: torch.FloatTensor):\n",
    "        y_n = y.numpy()\n",
    "        self.lb.fit(list(range(0,10)))\n",
    "        y_one_hot = self.lb.transform(y_n)\n",
    "        floatTensor = torch.FloatTensor(y_one_hot)\n",
    "        return floatTensor\n",
    "        \n",
    "    def encode(self, x, y):\n",
    "        y_c = self.to_categrical(y)\n",
    "        #输入样本和标签y的one-hot向量连接\n",
    "        con = torch.cat((x, y_c), 1)\n",
    "        h1 = F.relu(self.fc1(con))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        #训练时使用重参数化技巧，测试时不用。（测试时应该可以用）\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z, y):\n",
    "        y_c = self.to_categrical(y)\n",
    "        #解码器的输入：将z和y的one-hot向量连接\n",
    "        cat = torch.cat((z, y_c), 1)\n",
    "        h3 = F.relu(self.fc3(cat))\n",
    "        return F.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        mu, logvar = self.encode(x.view(-1, 784), y)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z, y), mu, logvar\n",
    "\n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, size_average=False)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD\n",
    "\n",
    "model = CVAE().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    #Sets the module in training mode.\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "#     batch_idx, (data, label) =enumerate(train_loader).__next__()\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        data = data.to(device) #[64, 1, 28, 28]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, logvar = model(data, label)\n",
    "#         print(recon_batch.shape) #[64, 794]\n",
    "        #训练样本展平，在每个样本后面连接标签的one-hot向量\n",
    "        flat_data = data.view(-1, data.shape[2]*data.shape[3])\n",
    "#         print(data.shape, flat_data.shape)\n",
    "        y_condition = model.to_categrical(label)\n",
    "        con = torch.cat((flat_data, y_condition), 1)\n",
    "        \n",
    "        loss = loss_function(recon_batch, con, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch,\n",
    "                batch_idx * len(data),\n",
    "                len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "index, (data, label) =enumerate(train_loader).__next__()\n",
    "print(index, data.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_cat)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m====> Test set loss: \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(test_loss))\n\u001b[1;32m     32\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, EPOCH \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> 33\u001b[0m     train(epoch)\n\u001b[1;32m     34\u001b[0m     test(epoch)\n\u001b[1;32m     35\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     36\u001b[0m         \u001b[39m#采样过程\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      8\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device) \u001b[39m#[64, 1, 28, 28]\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 12\u001b[0m         recon_batch, mu, logvar \u001b[39m=\u001b[39m model(data, label)\n\u001b[1;32m     13\u001b[0m \u001b[39m#         print(recon_batch.shape) #[64, 794]\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         \u001b[39m#训练样本展平，在每个样本后面连接标签的one-hot向量\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         flat_data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, data\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]\u001b[39m*\u001b[39mdata\u001b[39m.\u001b[39mshape[\u001b[39m3\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/sa/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[2], line 44\u001b[0m, in \u001b[0;36mCVAE.forward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, y):\n\u001b[0;32m---> 44\u001b[0m     mu, logvar \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode(x\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m784\u001b[39;49m), y)\n\u001b[1;32m     45\u001b[0m     z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreparameterize(mu, logvar)\n\u001b[1;32m     46\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecode(z, y), mu, logvar\n",
      "Cell \u001b[0;32mIn[2], line 23\u001b[0m, in \u001b[0;36mCVAE.encode\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     21\u001b[0m y_c \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_categrical(y)\n\u001b[1;32m     22\u001b[0m \u001b[39m#输入样本和标签y的one-hot向量连接\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m con \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat((x, y_c), \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     24\u001b[0m h1 \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(con))\n\u001b[1;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc21(h1), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc22(h1)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_cat)"
     ]
    }
   ],
   "source": [
    "def test(epoch):\n",
    "    #Sets the module in evaluation mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (data, label) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data, label)\n",
    "            \n",
    "            flat_data = data.view(-1, data.shape[2]*data.shape[3])\n",
    "            \n",
    "            y_condition = model.to_categrical(label)\n",
    "            con = torch.cat((flat_data, y_condition), 1)\n",
    "            test_loss += loss_function(recon_batch, con, mu, logvar).item()\n",
    "\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                recon_image = recon_batch[:, 0:recon_batch.shape[1]-10]\n",
    "                print(recon_image.shape)\n",
    "                recon_image = recon_image.view(BATCH_SIZE, 1, 28,28)\n",
    "                print('---',recon_image.shape)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_image.view(BATCH_SIZE, 1, 28, 28)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                         'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCH + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    with torch.no_grad():\n",
    "        #采样过程\n",
    "        sample = torch.randn(64, 20).to(device)\n",
    "      \n",
    "        c = np.zeros(shape=(sample.shape[0],))\n",
    "        rand = np.random.randint(0, 10)\n",
    "        print(f\"Random number: {rand}\")\n",
    "        c[:] = rand\n",
    "        c = torch.FloatTensor(c)\n",
    "        sample = model.decode(sample, c).cpu()\n",
    "        #模型的输出矩阵：每一行的末尾都加了one-hot向量，要去掉这个one-hot向量再转换为图片。\n",
    "        generated_image = sample[:, 0:sample.shape[1]-10]\n",
    "        \n",
    "        \n",
    "        save_image(generated_image.view(64, 1, 28, 28),\n",
    "                   'results/sample_' + str(epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
